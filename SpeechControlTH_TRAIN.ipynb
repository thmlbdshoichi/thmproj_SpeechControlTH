{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Audio Recognition using Tensorflow\n",
    "### Speech Recognition for Controlling Robot (THAI COMMAND)\n",
    "#### By. Arunwat Moonbung\n",
    "#### SPECIAL THANKS TO \"Leandro Roser\"\n",
    "#### FOR AUDIO-PREPROCESSING e.g. AUDIO-AUGMENTATION TECHNIQUES, DATA LOADING, DATA INTEGRITY OBSERVE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import IPython.display as ipd\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,LabelBinarizer\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.python.client import device_lib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently using Tensorflow 2.8.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0,1'\n",
    "print(f\"Currently using Tensorflow {tf.__version__}\")\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(tf.test.gpu_device_name())\n",
    "tf.random.set_seed(221)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASS AND FUNCTION DEFINATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join(\"Data_Thai\",\"train\")\n",
    "DATASET_JSON = os.path.join(\"Data_Thai\",\"classmap.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_audio(signal, NUM_SAMPLES_TO_CONSIDER):\n",
    "    if len(signal) >= NUM_SAMPLES_TO_CONSIDER:\n",
    "        return signal[:NUM_SAMPLES_TO_CONSIDER]\n",
    "    else:\n",
    "        return np.pad(signal, pad_width=(NUM_SAMPLES_TO_CONSIDER - len(signal), 0), mode='constant', constant_values=(0, 0))\n",
    "    \n",
    "def pad_audio_sec(self, signal, DURATION, NUM_SAMPLES_TO_CONSIDER):\n",
    "        TOTAL_SAMPLE = DURATION*NUM_SAMPLES_TO_CONSIDER\n",
    "        if len(signal) >= TOTAL_SAMPLE:\n",
    "            return signal[:TOTAL_SAMPLE]\n",
    "        else:\n",
    "            #return np.pad(signal, pad_width=(0, TOTAL_SAMPLE - len(signal)), mode='constant', constant_values=(0, 0)) # PAD หลัง\n",
    "            return np.pad(signal, pad_width=(TOTAL_SAMPLE - len(signal), 0), mode='constant', constant_values=(0, 0)) # PAD หน้า\n",
    "\n",
    "def chop_audio(signal, NUM_SAMPLES_TO_CONSIDER=16000):\n",
    "    while True:\n",
    "        beg = np.random.randint(0, len(signal) - NUM_SAMPLES_TO_CONSIDER)\n",
    "        yield signal[beg: beg + NUM_SAMPLES_TO_CONSIDER]\n",
    "\n",
    "def choose_background_generator(signal, backgrounds, max_alpha=0.7):\n",
    "    if backgrounds is None:\n",
    "        return signal\n",
    "    my_gen = backgrounds[np.random.randint(len(backgrounds))]\n",
    "    background = next(my_gen) * np.random.uniform(0, max_alpha)\n",
    "    augmented_data = signal + background\n",
    "    augmented_data = augmented_data.astype(type(signal[0]))\n",
    "    return augmented_data\n",
    "\n",
    "def random_shift(signal, NUM_SAMPLES_TO_CONSIDER=16000, shift_max=0.2):\n",
    "    shift = np.random.randint(NUM_SAMPLES_TO_CONSIDER * shift_max)\n",
    "    out = np.roll(signal, shift)\n",
    "    # Time shift\n",
    "    if shift > 0:\n",
    "        out[:shift] = 0\n",
    "    else:\n",
    "        out[shift:] = 0\n",
    "    return out\n",
    "\n",
    "def random_change_pitch(signal, NUM_SAMPLES_TO_CONSIDER=16000):\n",
    "    pitch_factor = np.random.randint(1, 4)\n",
    "    out = librosa.effects.pitch_shift(y=signal, sr=NUM_SAMPLES_TO_CONSIDER, n_steps=pitch_factor)\n",
    "    return out\n",
    "\n",
    "def random_speed_up(signal):\n",
    "    where = [\"start\", \"end\"][np.random.randint(0, 1)]\n",
    "    speed_factor = np.random.uniform(0, 0.5)\n",
    "    up = librosa.effects.time_stretch(y=signal, rate=1 + speed_factor)\n",
    "    up_len = up.shape[0]\n",
    "    if where == \"end\":\n",
    "        up = np.concatenate((up, np.zeros((signal.shape[0] - up_len,))))\n",
    "    else:\n",
    "        up = np.concatenate((np.zeros((signal.shape[0] - up_len,)), up))\n",
    "    return up\n",
    "\n",
    "def get_image_list(train_audio_path):\n",
    "    classes = os.listdir(train_audio_path)\n",
    "    classes = [thisclass for thisclass in classes if thisclass != '_background_noise_']\n",
    "    index = [i for i,j in enumerate(classes)]\n",
    "    outlist = []\n",
    "    labels = []\n",
    "    text_labels = dict(zip(classes, index))\n",
    "    for thisindex, thisclass in zip(index, classes):\n",
    "        filelist = [f for f in os.listdir(os.path.join(train_audio_path, thisclass)) if f.endswith('.wav')]\n",
    "        filelist = [os.path.join(train_audio_path, thisclass, x) for x in filelist]\n",
    "        outlist.append(filelist)\n",
    "        labels.append(np.full(len(filelist), fill_value=thisindex))\n",
    "    try:\n",
    "        with open(DATASET_JSON, \"w\") as f:\n",
    "            json.dump(text_labels, f, indent=4)\n",
    "        print(f\"#: SAVING CLASS LABEL MAPPING.. AT {train_audio_path}\")\n",
    "    except:\n",
    "        print(\"!: ERROR WHILE SAVING .json file\")\n",
    "        \n",
    "    return outlist, labels, text_labels\n",
    "\n",
    "def split_train_test_stratified_shuffle(images_list, labels, train_size=0.7):\n",
    "    classes_size = [len(x) for x in images_list]\n",
    "    classes_vector = [np.arange(x) for x in classes_size]\n",
    "    total = np.sum(classes_size)\n",
    "    total_train = [int(train_size * total * x) for x in classes_size / total]\n",
    "    train_index = [np.random.choice(x, y, replace=False) for x,y in zip(classes_size, total_train)]\n",
    "    validation_index = [np.setdiff1d(i,j) for i,j in zip(classes_vector,train_index)]\n",
    "    train_set = [np.array(x)[idx] for x,idx in zip(images_list, train_index)]\n",
    "    validation_set = [np.array(x)[idx] for x,idx in zip(images_list, validation_index)]\n",
    "    train_labels = [np.array(x)[idx] for x,idx in zip(labels,train_index)]\n",
    "    validation_labels = [np.array(x)[idx] for x,idx in zip(labels, validation_index)]\n",
    "    # ----------------------------------------------------------------------------------------- \n",
    "    train_set = np.array([element for array in train_set for element in array])\n",
    "    validation_set = np.array([element for array in validation_set for element in array])\n",
    "    train_labels = np.array([element for array in train_labels for element in array])\n",
    "    validation_labels = np.array([element for array in validation_labels for element in array])\n",
    "    # -----------------------------------------------------------------------------------------\n",
    "    train_shuffle = np.random.permutation(len(train_set))\n",
    "    validation_shuffle = np.random.permutation(len(validation_set))\n",
    "    train_set = train_set[train_shuffle]\n",
    "    validation_set = validation_set[validation_shuffle]\n",
    "    train_labels = train_labels[train_shuffle]\n",
    "    validation_labels = validation_labels[validation_shuffle]\n",
    "    return train_set, train_labels, validation_set, validation_labels\n",
    "\n",
    "def preprocess_data(file_path, background_generator, n_mfcc=40, hop_length=512, n_fft=4096, NUM_SAMPLES_TO_CONSIDER=16000, threshold=0.7):\n",
    "    # Downsample to NUM_SAMPLES_TO_CONSIDER Hz\n",
    "    signal, sr = librosa.load(file_path, sr=NUM_SAMPLES_TO_CONSIDER)\n",
    "    signal = pad_audio(signal, sr)\n",
    "    if np.random.uniform(0, 1) > threshold:\n",
    "        # ADD NOISE TO 30% OF DATA\n",
    "        signal = choose_background_generator(signal, background_generator)\n",
    "    if np.random.uniform(0, 1) > threshold:\n",
    "        signal = random_shift(signal)\n",
    "    if np.random.uniform(0, 1) > threshold:\n",
    "        signal = random_change_pitch(signal)\n",
    "    if np.random.uniform(0, 1) > threshold:\n",
    "        signal = random_speed_up(signal)\n",
    "    MFCCs = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=n_mfcc) # Transpose for sklearn\n",
    "    MFCCs = np.moveaxis(MFCCs, 1, 0)\n",
    "    #scaler = MinMaxScaler() # OPTIONAL FOR Scaling\n",
    "    scaler = StandardScaler() \n",
    "    MFCCs_scaled = scaler.fit_transform(MFCCs)\n",
    "    # MFCCs Input Shape -> (NUM_SAMPLE x NUM_MFCC_COEFFICIENT x 1)\n",
    "    return MFCCs_scaled.reshape(MFCCs_scaled.shape[0], MFCCs_scaled.shape[1], 1)\n",
    "\n",
    "class data_generator(keras.utils.Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size, background_generator):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.background_generator = background_generator\n",
    "    \n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.x) / self.batch_size)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx_from = idx * self.batch_size\n",
    "        idx_to = (idx + 1) * self.batch_size\n",
    "        batch_x = self.x[idx_from:idx_to]\n",
    "        batch_y = self.y[idx_from:idx_to]\n",
    "        x = [preprocess_data(elem, self.background_generator) for elem in batch_x]\n",
    "        y = batch_y\n",
    "        return np.array(x).astype(np.float32), np.array(y).astype(np.float32)\n",
    "        #return np.array(x), np.array(y)\n",
    "    \n",
    "def build_model(num_classes, input_shape):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=input_shape))\n",
    "    model.add(keras.layers.Conv2D(filters=32, kernel_size=(3,3), \n",
    "                                padding=\"same\", activation=\"relu\",\n",
    "                                kernel_regularizer=keras.regularizers.l2(0.001)))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(keras.layers.Conv2D(filters=64, kernel_size=(3,3),\n",
    "                                padding=\"same\", activation=\"relu\",\n",
    "                                kernel_regularizer=keras.regularizers.l2(0.001)))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(keras.layers.Conv2D(filters=128, kernel_size=(3,3),\n",
    "                                padding=\"same\", activation=\"relu\",\n",
    "                                kernel_regularizer=keras.regularizers.l2(0.001)))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(keras.layers.Conv2D(filters=256, kernel_size=(3,3),\n",
    "                                padding=\"same\", activation=\"relu\",\n",
    "                                kernel_regularizer=keras.regularizers.l2(0.001)))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(keras.layers.Dropout(0.25))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def multiclass_roc(y_test, y_pred, average=\"macro\"):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    all_labels = np.unique(y_test)\n",
    "    \n",
    "    for (idx, c_label) in enumerate(all_labels):\n",
    "        fpr, tpr, thresholds = roc_curve(y_test[:,idx].astype(int), y_pred[:,idx])\n",
    "        c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)' % (c_label, auc(fpr, tpr)))\n",
    "    c_ax.plot(fpr, fpr, 'b-', label = 'Random Guessing')\n",
    "    return roc_auc_score(y_test, y_pred, average=average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''train_audio_sample = os.path.join(\"Data_Thai\",\"train\",\"backward\",\"b1.wav\")\n",
    "x,sr = librosa.load(train_audio_sample, sr = 16000)\n",
    "x = pad_audio(x, sr)\n",
    "choose_background_generator(x, background_generator)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING DATASET / VERIFY LOADING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA WITH BACKGROUNDS\n",
    "wavfiles = glob.glob(os.path.join(DATASET_PATH, \"_background_noise_/*wav\"))\n",
    "wavfiles = [librosa.load(elem, sr = 16000)[0] for elem in wavfiles]\n",
    "# wavfile คือ array ของไฟล์เสียง\n",
    "background_generator = [chop_audio(x) for x in wavfiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#: SAVING CLASS LABEL MAPPING.. AT Data_Thai\\train\n"
     ]
    }
   ],
   "source": [
    "# TRAINING DATA PATHS, \n",
    "# SPLIT TRAIN-TEST VIA STRATIFIED SAMPLING, \n",
    "# CALL A DATA GENERATOR FOR KERAS\n",
    "# LOAD TRAIN\n",
    "images_list, labels, classes_map = get_image_list(DATASET_PATH)\n",
    "train_set, train_labels, validation_set, validation_labels = split_train_test_stratified_shuffle(images_list, labels)\n",
    "train_datagen = data_generator(x_set=train_set, y_set=train_labels, batch_size=32, background_generator=background_generator)\n",
    "validation_datagen = data_generator(x_set=validation_set, y_set=validation_labels, batch_size=32, background_generator=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(train_datagen[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''display(images_list)\n",
    "display(labels)\n",
    "display(classes_map)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CHECK IF TRAINING DATASET ALSO CONTAIN IN VALIDATION DATASET? // ควรเป็น False เพราะต้องไม่มีตัวไหนที่ซ้ำกัน\n",
    "inv_map =  {v: k for k, v in classes_map.items()}\n",
    "any_present=[i in validation_set for i in train_set]\n",
    "np.any(any_present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Data_Thai\\\\train\\\\backward\\\\b913.wav',\n",
       "        'Data_Thai\\\\train\\\\release\\\\re3.wav',\n",
       "        'Data_Thai\\\\train\\\\search\\\\se804.wav',\n",
       "        'Data_Thai\\\\train\\\\backward\\\\b913.wav',\n",
       "        'Data_Thai\\\\train\\\\forward\\\\f815.wav',\n",
       "        'Data_Thai\\\\train\\\\release\\\\re201.wav',\n",
       "        'Data_Thai\\\\train\\\\turnleft\\\\l4.wav',\n",
       "        'Data_Thai\\\\train\\\\grab\\\\g711.wav',\n",
       "        'Data_Thai\\\\train\\\\stop\\\\s502.wav',\n",
       "        'Data_Thai\\\\train\\\\search\\\\se807.wav'], dtype='<U34'),\n",
       " ['backward',\n",
       "  'release',\n",
       "  'search',\n",
       "  'backward',\n",
       "  'forward',\n",
       "  'release',\n",
       "  'turnleft',\n",
       "  'grab',\n",
       "  'stop',\n",
       "  'search'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CHECK MATCHING FILE .WAV FROM (train_set) and LABELS FROM (train_labels) \n",
    "# โฟลเดอร์ไฟล์ ต้องตรงกับ Label ข้างล่างตามลำดับ ไม่งั้นแสดงว่า Data-pre ผิดพลาด\n",
    "test1 = np.random.randint(10, 100, 10)\n",
    "train_set[test1],[inv_map[int(i)] for i in train_labels[test1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           1\n",
      "0  12.590799\n",
      "1  12.590799\n",
      "2  11.864407\n",
      "3  12.590799\n",
      "4  12.106538\n",
      "5  12.348668\n",
      "6  12.832930\n",
      "7  13.075061\n",
      "           1\n",
      "0  12.509144\n",
      "1  12.655450\n",
      "2  11.923921\n",
      "3  12.582297\n",
      "4  12.143380\n",
      "5  12.435991\n",
      "6  12.728603\n",
      "7  13.021214\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1VALIDATION_SET</th>\n",
       "      <th>1ENTIRE_SET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.509144</td>\n",
       "      <td>12.590799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.655450</td>\n",
       "      <td>12.590799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.923921</td>\n",
       "      <td>11.864407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.582297</td>\n",
       "      <td>12.590799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.143380</td>\n",
       "      <td>12.106538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1VALIDATION_SET  1ENTIRE_SET\n",
       "0        12.509144    12.590799\n",
       "1        12.655450    12.590799\n",
       "2        11.923921    11.864407\n",
       "3        12.582297    12.590799\n",
       "4        12.143380    12.106538"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STRATIFIED SAMPLING WORKS\n",
    "# CHECK UNIQUE VALUE IN NUM_CLASSES (unique) [0, 1, ...]\n",
    "# COUNT NUM_SAMPLE IN EACH UNIQUE VALUE (counts) [500, 500, ...]\n",
    "unique, counts = np.unique(validation_labels, return_counts=True)\n",
    "x = dict(zip(unique, counts)) # CONVERT IT INTO DICTIONARY {label: counts}\n",
    "out = pd.DataFrame(sorted(x.items(), key=lambda kv: kv[0])) #CREATE DATAFRAME FROM DICTIONARY (x)\n",
    "out.drop(0, inplace = True, axis = 1) # DROP EXEEDS(INDEX) COLUMNS\n",
    "out = out.apply(lambda x: 100 * x/sum(x)) # CONVERT COUNT TO PERCENTAGE OF EACH UNIQUE LABEL COUNT เช่น 0:49.89 1:50.10 (%)\n",
    "\n",
    "total_labels = [y for x in labels for y in x] # LIST TO CONTAIN ALL LABELS OF DATA[0,0,0,1,0,0,1]\n",
    "unique, counts = np.unique(total_labels, return_counts=True)\n",
    "y=dict(zip(unique, counts)) #CONVERT INTO DICT {label: counts} (FOR ENTIRE DATASET NO SPLIT)\n",
    "out2 = pd.DataFrame(sorted(y.items(), key=lambda kv: kv[0]))\n",
    "out2.drop(0, inplace = True, axis = 1)\n",
    "out2 = out2.apply(lambda x: 100 * x/sum(x))\n",
    "\n",
    "print(out)\n",
    "print(out2)\n",
    "display(out2.join(out, lsuffix='VALIDATION_SET', rsuffix='ENTIRE_SET')[:5])\n",
    "np.allclose(out.iloc[:,0].values, out2.iloc[:,0].values,  atol=0.01) \n",
    "# Returns True if two arrays are element-wise equal within a tolerance.\n",
    "# ใช้ดูว่าการแบ่งสัดส่วนของ Class target ของ VALIDATION_SET เมื่อเทียบกับ ENTIRE_SET ใกล้เคียงกันไหม"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING PROCESS\n",
    "#### MODEL BUILDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n"
     ]
    }
   ],
   "source": [
    "# check format, channel last, (x_train.shape[0], rows, cols, 1)\n",
    "print(keras.backend.image_data_format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROWS = 32\n",
    "COLUMNS = 40\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.001\n",
    "optimizer = keras.optimizers.Adam(learning_rate = LEARNING_RATE)\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "MODEL_PATH = \"models\"\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    os.makedirs(MODEL_PATH)\n",
    "train_size = train_set.shape[0]\n",
    "validation_size = validation_set.shape[0]\n",
    "steps_per_epoch = train_size//BATCH_SIZE\n",
    "\n",
    "checkpoint_filepath = os.path.join(MODEL_PATH, \n",
    "                                'model.{epoch:02d}-{val_sparse_categorical_accuracy:.2f}-{val_loss:.2f}.h5')\n",
    "\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "                                                    save_weights_only=False,\n",
    "                                                    monitor='val_sparse_categorical_accuracy',\n",
    "                                                    mode='max',\n",
    "                                                    save_best_only=True,\n",
    "                                                    verbose=1)\n",
    "\n",
    "reduce_lr_callback = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                                                    patience=3, min_lr=1e-5, vebose=1)\n",
    "earlystop_callback = keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "                                                min_delta=1e-3,\n",
    "                                                patience=5,\n",
    "                                                verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 40, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 20, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 20, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 10, 64)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 10, 128)        73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 5, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 5, 256)         295168    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 2, 2, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               131200    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 1032      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 520,072\n",
      "Trainable params: 520,072\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "#model = build_model(8, (ROWS, COLUMNS, 1))\n",
    "model = build_model(len(classes_map), (ROWS, COLUMNS, 1))\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=[acc_metric])   \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAINING PROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\Shoichi/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>t:\\Shoichi\\Shoichi's Learning\\BrownienLab\\NLP\\SpeechControl\\wandb\\run-20220315_161913-3j3xpg6l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/thmlbdshoichi/NLP_SpeechControlTH/runs/3j3xpg6l\" target=\"_blank\">glad-pyramid-25</a></strong> to <a href=\"https://wandb.ai/thmlbdshoichi/NLP_SpeechControlTH\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# WANDB LOGING\n",
    "# INITIALIZE WANDB PROJECT AND SPECIFY HYPERPARAMETER DATA\n",
    "run = wandb.init(project='NLP_SpeechControlTH',entity=\"thmlbdshoichi\") #entity = username wandb\n",
    "wandb.config = {\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE\n",
    "}\n",
    "config = wandb.config # CONFIGURE OF EXPERIMENT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "29/29 [==============================] - ETA: 0s - loss: 2.3197 - sparse_categorical_accuracy: 0.1746\n",
      "Epoch 1: val_sparse_categorical_accuracy improved from -inf to 0.28385, saving model to models\\model.01-0.28-2.17.h5\n",
      "29/29 [==============================] - 26s 763ms/step - loss: 2.3197 - sparse_categorical_accuracy: 0.1746 - val_loss: 2.1685 - val_sparse_categorical_accuracy: 0.2839 - lr: 0.0010 - _timestamp: 1647335999.0000 - _runtime: 46.0000\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - ETA: 0s - loss: 1.7785 - sparse_categorical_accuracy: 0.4062\n",
      "Epoch 2: val_sparse_categorical_accuracy improved from 0.28385 to 0.61198, saving model to models\\model.02-0.61-1.27.h5\n",
      "29/29 [==============================] - 21s 719ms/step - loss: 1.7785 - sparse_categorical_accuracy: 0.4062 - val_loss: 1.2729 - val_sparse_categorical_accuracy: 0.6120 - lr: 0.0010 - _timestamp: 1647336020.0000 - _runtime: 67.0000\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - ETA: 0s - loss: 1.0583 - sparse_categorical_accuracy: 0.6649\n",
      "Epoch 3: val_sparse_categorical_accuracy improved from 0.61198 to 0.77083, saving model to models\\model.03-0.77-0.82.h5\n",
      "29/29 [==============================] - 20s 704ms/step - loss: 1.0583 - sparse_categorical_accuracy: 0.6649 - val_loss: 0.8178 - val_sparse_categorical_accuracy: 0.7708 - lr: 0.0010 - _timestamp: 1647336040.0000 - _runtime: 87.0000\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.6700 - sparse_categorical_accuracy: 0.8384\n",
      "Epoch 4: val_sparse_categorical_accuracy improved from 0.77083 to 0.89583, saving model to models\\model.04-0.90-0.50.h5\n",
      "29/29 [==============================] - 21s 733ms/step - loss: 0.6700 - sparse_categorical_accuracy: 0.8384 - val_loss: 0.4954 - val_sparse_categorical_accuracy: 0.8958 - lr: 0.0010 - _timestamp: 1647336061.0000 - _runtime: 108.0000\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.4924 - sparse_categorical_accuracy: 0.8948\n",
      "Epoch 5: val_sparse_categorical_accuracy improved from 0.89583 to 0.92708, saving model to models\\model.05-0.93-0.38.h5\n",
      "29/29 [==============================] - 21s 721ms/step - loss: 0.4924 - sparse_categorical_accuracy: 0.8948 - val_loss: 0.3815 - val_sparse_categorical_accuracy: 0.9271 - lr: 0.0010 - _timestamp: 1647336082.0000 - _runtime: 129.0000\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.4427 - sparse_categorical_accuracy: 0.9187\n",
      "Epoch 6: val_sparse_categorical_accuracy improved from 0.92708 to 0.93490, saving model to models\\model.06-0.93-0.38.h5\n",
      "29/29 [==============================] - 20s 696ms/step - loss: 0.4427 - sparse_categorical_accuracy: 0.9187 - val_loss: 0.3836 - val_sparse_categorical_accuracy: 0.9349 - lr: 0.0010 - _timestamp: 1647336102.0000 - _runtime: 149.0000\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.3739 - sparse_categorical_accuracy: 0.9414\n",
      "Epoch 7: val_sparse_categorical_accuracy improved from 0.93490 to 0.94531, saving model to models\\model.07-0.95-0.33.h5\n",
      "29/29 [==============================] - 21s 725ms/step - loss: 0.3739 - sparse_categorical_accuracy: 0.9414 - val_loss: 0.3298 - val_sparse_categorical_accuracy: 0.9453 - lr: 0.0010 - _timestamp: 1647336123.0000 - _runtime: 170.0000\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.3373 - sparse_categorical_accuracy: 0.9458\n",
      "Epoch 8: val_sparse_categorical_accuracy improved from 0.94531 to 0.97917, saving model to models\\model.08-0.98-0.26.h5\n",
      "29/29 [==============================] - 20s 684ms/step - loss: 0.3373 - sparse_categorical_accuracy: 0.9458 - val_loss: 0.2643 - val_sparse_categorical_accuracy: 0.9792 - lr: 0.0010 - _timestamp: 1647336143.0000 - _runtime: 190.0000\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.3361 - sparse_categorical_accuracy: 0.9555\n",
      "Epoch 9: val_sparse_categorical_accuracy improved from 0.97917 to 0.98177, saving model to models\\model.09-0.98-0.24.h5\n",
      "29/29 [==============================] - 21s 732ms/step - loss: 0.3361 - sparse_categorical_accuracy: 0.9555 - val_loss: 0.2399 - val_sparse_categorical_accuracy: 0.9818 - lr: 0.0010 - _timestamp: 1647336164.0000 - _runtime: 211.0000\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.2706 - sparse_categorical_accuracy: 0.9729\n",
      "Epoch 10: val_sparse_categorical_accuracy did not improve from 0.98177\n",
      "29/29 [==============================] - 20s 695ms/step - loss: 0.2706 - sparse_categorical_accuracy: 0.9729 - val_loss: 0.2296 - val_sparse_categorical_accuracy: 0.9792 - lr: 0.0010 - _timestamp: 1647336184.0000 - _runtime: 231.0000\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.2425 - sparse_categorical_accuracy: 0.9772\n",
      "Epoch 11: val_sparse_categorical_accuracy did not improve from 0.98177\n",
      "29/29 [==============================] - 21s 719ms/step - loss: 0.2425 - sparse_categorical_accuracy: 0.9772 - val_loss: 0.2257 - val_sparse_categorical_accuracy: 0.9766 - lr: 0.0010 - _timestamp: 1647336205.0000 - _runtime: 252.0000\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.2403 - sparse_categorical_accuracy: 0.9740\n",
      "Epoch 12: val_sparse_categorical_accuracy did not improve from 0.98177\n",
      "29/29 [==============================] - 21s 716ms/step - loss: 0.2403 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.2337 - val_sparse_categorical_accuracy: 0.9766 - lr: 0.0010 - _timestamp: 1647336225.0000 - _runtime: 272.0000\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.2453 - sparse_categorical_accuracy: 0.9707\n",
      "Epoch 13: val_sparse_categorical_accuracy improved from 0.98177 to 0.98958, saving model to models\\model.13-0.99-0.20.h5\n",
      "29/29 [==============================] - 21s 731ms/step - loss: 0.2453 - sparse_categorical_accuracy: 0.9707 - val_loss: 0.1997 - val_sparse_categorical_accuracy: 0.9896 - lr: 0.0010 - _timestamp: 1647336246.0000 - _runtime: 293.0000\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.2386 - sparse_categorical_accuracy: 0.9740\n",
      "Epoch 14: val_sparse_categorical_accuracy did not improve from 0.98958\n",
      "29/29 [==============================] - 21s 718ms/step - loss: 0.2386 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.2062 - val_sparse_categorical_accuracy: 0.9870 - lr: 0.0010 - _timestamp: 1647336267.0000 - _runtime: 314.0000\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.2266 - sparse_categorical_accuracy: 0.9816\n",
      "Epoch 15: val_sparse_categorical_accuracy did not improve from 0.98958\n",
      "29/29 [==============================] - 21s 713ms/step - loss: 0.2266 - sparse_categorical_accuracy: 0.9816 - val_loss: 0.1975 - val_sparse_categorical_accuracy: 0.9870 - lr: 0.0010 - _timestamp: 1647336288.0000 - _runtime: 335.0000\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.1921 - sparse_categorical_accuracy: 0.9892\n",
      "Epoch 16: val_sparse_categorical_accuracy did not improve from 0.98958\n",
      "29/29 [==============================] - 20s 711ms/step - loss: 0.1921 - sparse_categorical_accuracy: 0.9892 - val_loss: 0.1802 - val_sparse_categorical_accuracy: 0.9870 - lr: 0.0010 - _timestamp: 1647336308.0000 - _runtime: 355.0000\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.2130 - sparse_categorical_accuracy: 0.9783\n",
      "Epoch 17: val_sparse_categorical_accuracy did not improve from 0.98958\n",
      "29/29 [==============================] - 20s 708ms/step - loss: 0.2130 - sparse_categorical_accuracy: 0.9783 - val_loss: 0.1957 - val_sparse_categorical_accuracy: 0.9870 - lr: 0.0010 - _timestamp: 1647336328.0000 - _runtime: 375.0000\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.2004 - sparse_categorical_accuracy: 0.9772\n",
      "Epoch 18: val_sparse_categorical_accuracy did not improve from 0.98958\n",
      "29/29 [==============================] - 21s 717ms/step - loss: 0.2004 - sparse_categorical_accuracy: 0.9772 - val_loss: 0.1759 - val_sparse_categorical_accuracy: 0.9870 - lr: 0.0010 - _timestamp: 1647336349.0000 - _runtime: 396.0000\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.1932 - sparse_categorical_accuracy: 0.9848\n",
      "Epoch 19: val_sparse_categorical_accuracy did not improve from 0.98958\n",
      "29/29 [==============================] - 20s 688ms/step - loss: 0.1932 - sparse_categorical_accuracy: 0.9848 - val_loss: 0.1785 - val_sparse_categorical_accuracy: 0.9844 - lr: 0.0010 - _timestamp: 1647336369.0000 - _runtime: 416.0000\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.1910 - sparse_categorical_accuracy: 0.9859\n",
      "Epoch 20: val_sparse_categorical_accuracy did not improve from 0.98958\n",
      "29/29 [==============================] - 20s 688ms/step - loss: 0.1910 - sparse_categorical_accuracy: 0.9859 - val_loss: 0.1801 - val_sparse_categorical_accuracy: 0.9896 - lr: 0.0010 - _timestamp: 1647336389.0000 - _runtime: 436.0000\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.1967 - sparse_categorical_accuracy: 0.9837\n",
      "Epoch 21: val_sparse_categorical_accuracy did not improve from 0.98958\n",
      "29/29 [==============================] - 20s 687ms/step - loss: 0.1967 - sparse_categorical_accuracy: 0.9837 - val_loss: 0.1825 - val_sparse_categorical_accuracy: 0.9844 - lr: 0.0010 - _timestamp: 1647336409.0000 - _runtime: 456.0000\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.1659 - sparse_categorical_accuracy: 0.9913\n",
      "Epoch 22: val_sparse_categorical_accuracy improved from 0.98958 to 0.99479, saving model to models\\model.22-0.99-0.15.h5\n",
      "29/29 [==============================] - 21s 718ms/step - loss: 0.1659 - sparse_categorical_accuracy: 0.9913 - val_loss: 0.1511 - val_sparse_categorical_accuracy: 0.9948 - lr: 2.0000e-04 - _timestamp: 1647336430.0000 - _runtime: 477.0000\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.1655 - sparse_categorical_accuracy: 0.9892\n",
      "Epoch 23: val_sparse_categorical_accuracy improved from 0.99479 to 0.99740, saving model to models\\model.23-1.00-0.14.h5\n",
      "29/29 [==============================] - 20s 697ms/step - loss: 0.1655 - sparse_categorical_accuracy: 0.9892 - val_loss: 0.1430 - val_sparse_categorical_accuracy: 0.9974 - lr: 2.0000e-04 - _timestamp: 1647336450.0000 - _runtime: 497.0000\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.1631 - sparse_categorical_accuracy: 0.9913\n",
      "Epoch 24: val_sparse_categorical_accuracy did not improve from 0.99740\n",
      "29/29 [==============================] - 20s 695ms/step - loss: 0.1631 - sparse_categorical_accuracy: 0.9913 - val_loss: 0.1515 - val_sparse_categorical_accuracy: 0.9948 - lr: 2.0000e-04 - _timestamp: 1647336470.0000 - _runtime: 517.0000\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.1654 - sparse_categorical_accuracy: 0.9881\n",
      "Epoch 25: val_sparse_categorical_accuracy did not improve from 0.99740\n",
      "29/29 [==============================] - 20s 711ms/step - loss: 0.1654 - sparse_categorical_accuracy: 0.9881 - val_loss: 0.1552 - val_sparse_categorical_accuracy: 0.9948 - lr: 2.0000e-04 - _timestamp: 1647336490.0000 - _runtime: 537.0000\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.1628 - sparse_categorical_accuracy: 0.9881\n",
      "Epoch 26: val_sparse_categorical_accuracy did not improve from 0.99740\n",
      "29/29 [==============================] - 20s 692ms/step - loss: 0.1628 - sparse_categorical_accuracy: 0.9881 - val_loss: 0.1555 - val_sparse_categorical_accuracy: 0.9870 - lr: 2.0000e-04 - _timestamp: 1647336510.0000 - _runtime: 557.0000\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.1598 - sparse_categorical_accuracy: 0.9913\n",
      "Epoch 27: val_sparse_categorical_accuracy did not improve from 0.99740\n",
      "29/29 [==============================] - 19s 662ms/step - loss: 0.1598 - sparse_categorical_accuracy: 0.9913 - val_loss: 0.1440 - val_sparse_categorical_accuracy: 0.9948 - lr: 4.0000e-05 - _timestamp: 1647336529.0000 - _runtime: 576.0000\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.1642 - sparse_categorical_accuracy: 0.9881\n",
      "Epoch 28: val_sparse_categorical_accuracy did not improve from 0.99740\n",
      "29/29 [==============================] - 20s 706ms/step - loss: 0.1642 - sparse_categorical_accuracy: 0.9881 - val_loss: 0.1434 - val_sparse_categorical_accuracy: 0.9974 - lr: 4.0000e-05 - _timestamp: 1647336549.0000 - _runtime: 596.0000\n",
      "Epoch 28: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_datagen,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=validation_datagen,\n",
    "                    validation_steps=validation_size//BATCH_SIZE,\n",
    "                    callbacks=[earlystop_callback, reduce_lr_callback, checkpoint_callback, WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▆▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>█████████████████████▂▂▂▂▂▁▁</td></tr><tr><td>sparse_categorical_accuracy</td><td>▁▃▅▇▇▇██████████████████████</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_sparse_categorical_accuracy</td><td>▁▄▆▇▇▇▇█████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>22</td></tr><tr><td>best_val_loss</td><td>0.14301</td></tr><tr><td>epoch</td><td>27</td></tr><tr><td>loss</td><td>0.16418</td></tr><tr><td>lr</td><td>4e-05</td></tr><tr><td>sparse_categorical_accuracy</td><td>0.98807</td></tr><tr><td>val_loss</td><td>0.14341</td></tr><tr><td>val_sparse_categorical_accuracy</td><td>0.9974</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">glad-pyramid-25</strong>: <a href=\"https://wandb.ai/thmlbdshoichi/NLP_SpeechControlTH/runs/3j3xpg6l\" target=\"_blank\">https://wandb.ai/thmlbdshoichi/NLP_SpeechControlTH/runs/3j3xpg6l</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220315_161913-3j3xpg6l\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# WANDB.log\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EVALUDATE THE MODEL PERFORMANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''test_error, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"LOSS ERROR: {test_error*100:.3f}% | ACCURACY: {test_accuracy*100:.3f}%\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Keyword_Demo_v2:\n",
    "    def __init__(self, model_path, text_labels, plot=False):\n",
    "        if os.path.exists(model_path):\n",
    "            self.model = keras.models.load_model(model_path)\n",
    "            #self.model.summary()\n",
    "        else:\n",
    "            self.model = None\n",
    "        if os.path.exists(text_labels):\n",
    "            with open(text_labels, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "            self.text_labels = [k for k in data.keys()]\n",
    "        else:\n",
    "            self.txt_labels = None\n",
    "        self.plot = plot\n",
    "    \n",
    "    def predict(self, file_path):\n",
    "        # EXTRACT MFCCs\n",
    "        MFCCs = self.preprocess_data_test(file_path)\n",
    "        #MFCCs = MFCCs[np.newaxis, ...]\n",
    "        print(f\"INPUT SHAPE: {MFCCs.shape}\")\n",
    "        # PREDICT -> OUTPUT PROBABILITY\n",
    "        predictions = self.model.predict(MFCCs)\n",
    "        predicted_index = np.argmax(predictions)\n",
    "        predicted_conf = predictions[0][predicted_index]\n",
    "        predicted_label = self.text_labels[predicted_index]\n",
    "        if predicted_conf < 0.7:\n",
    "            predicted_label = 'OTHER_KEYWORDS'\n",
    "            print(f\"Keyword Detected '{predicted_label}' | ORIGINAL: '{self.text_labels[predicted_index]}' NUM:'{predicted_index}' Confidence: {predicted_conf*100:.2f}%\")\n",
    "        else:\n",
    "            print(f\"Keyword Detected '{predicted_label}' | 'NUM:{predicted_index}' Confidence: {predicted_conf*100:.2f}%\")\n",
    "        return predicted_label, predicted_conf\n",
    "    \n",
    "    def preprocess_data_test(self, file_path, n_mfcc=40, n_fft=4096, hop_length=512, NUM_SAMPLES_TO_CONSIDER=16000):\n",
    "        # LOAD AUDIO FILE\n",
    "        signal, sr = librosa.load(file_path, sr=NUM_SAMPLES_TO_CONSIDER)\n",
    "        signal = self.pad_audio(signal, sr)\n",
    "        # EXTRACT MFCCs\n",
    "        MFCCs = librosa.feature.mfcc(y=signal, n_mfcc=n_mfcc,\n",
    "                                    hop_length=hop_length,\n",
    "                                    n_fft=n_fft)\n",
    "        \n",
    "        # PLOT OR NOT\n",
    "        if self.plot:\n",
    "            librosa.display.specshow(MFCCs, sr=sr, hop_length=hop_length)\n",
    "            plt.title(f\"MFCCs Sample {file_path} (BEFORE MFCCs.T)\")\n",
    "            plt.xlabel(\"Time (sec)\")\n",
    "            plt.ylabel(\"MFCC\")\n",
    "            plt.colorbar()\n",
    "            plt.show()\n",
    "            \n",
    "        MFCCs = MFCCs.T # MFCCs = np.moveaxis(MFCCs, 1, 0)\n",
    "        scaler = StandardScaler()\n",
    "        MFCCs_scaled = scaler.fit_transform(MFCCs)\n",
    "        MFCCs_scaled = MFCCs_scaled.reshape(MFCCs_scaled.shape[0], MFCCs_scaled.shape[1], 1)\n",
    "        MFCCs_scaled = MFCCs_scaled[np.newaxis, ...]\n",
    "        # MFCCs Input Shape -> (NUM_SAMPLE x NUM_MFCC_COEFFICIENT x 1)\n",
    "        return MFCCs_scaled #IF ERROR BRING MFCCs_scaled back to this line\n",
    "\n",
    "    def pad_audio(self, signal, NUM_SAMPLES_TO_CONSIDER):\n",
    "        if len(signal) >= NUM_SAMPLES_TO_CONSIDER:\n",
    "            return signal[:NUM_SAMPLES_TO_CONSIDER]\n",
    "        else:\n",
    "            return np.pad(signal, pad_width=(NUM_SAMPLES_TO_CONSIDER - len(signal), 0), mode='constant', constant_values=(0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'models/model-best.h5'\n",
    "model_pred = keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1 b30.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'จับ' NUM:'2' Confidence: 13.93%\n",
      "# 2 b31.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 15.21%\n",
      "# 3 b32.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 14.98%\n",
      "# 4 b33.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 14.37%\n",
      "# 5 b34.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 14.35%\n",
      "# 6 b35.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 14.52%\n",
      "# 7 b36.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'จับ' NUM:'2' Confidence: 13.93%\n",
      "# 8 b37.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'หยุด' NUM:'5' Confidence: 14.02%\n",
      "# 9 b38.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 14.11%\n",
      "# 10 b39.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 14.26%\n",
      "# 11 b40.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 13.93%\n",
      "# 12 b71.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'หยุด' NUM:'5' Confidence: 15.50%\n",
      "# 13 b72.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'หยุด' NUM:'5' Confidence: 15.17%\n",
      "# 14 b73.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 15.60%\n",
      "# 15 f30.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 16.48%\n",
      "# 16 f31.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 14.69%\n",
      "# 17 f32.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 14.51%\n",
      "# 18 f33.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 14.18%\n",
      "# 19 f34.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 14.93%\n",
      "# 20 f35.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 16.24%\n",
      "# 21 f36.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'หยุด' NUM:'5' Confidence: 14.02%\n",
      "# 22 f37.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 14.37%\n",
      "# 23 f38.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 14.20%\n",
      "# 24 f39.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'หยุด' NUM:'5' Confidence: 14.28%\n",
      "# 25 f40.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 14.75%\n",
      "# 26 f71.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'หยุด' NUM:'5' Confidence: 14.99%\n",
      "# 27 f72.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 15.19%\n",
      "# 28 f73.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 16.31%\n",
      "# 29 g30.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 16.65%\n",
      "# 30 g31.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 14.92%\n",
      "# 31 g32.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'หยุด' NUM:'5' Confidence: 14.74%\n",
      "# 32 g33.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'หยุด' NUM:'5' Confidence: 16.33%\n",
      "# 33 g34.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'หยุด' NUM:'5' Confidence: 16.16%\n",
      "# 34 g35.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'หยุด' NUM:'5' Confidence: 17.40%\n",
      "# 35 g36.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 16.97%\n",
      "# 36 g37.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 16.37%\n",
      "# 37 g38.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 16.53%\n",
      "# 38 g39.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 19.00%\n",
      "# 39 g40.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'หยุด' NUM:'5' Confidence: 14.53%\n",
      "# 40 g71.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 20.63%\n",
      "# 41 g72.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 18.67%\n",
      "# 42 g73.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 16.96%\n",
      "# 43 l30.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 15.43%\n",
      "# 44 l31.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 15.03%\n",
      "# 45 l32.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 15.46%\n",
      "# 46 l33.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 13.87%\n",
      "# 47 l34.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 14.43%\n",
      "# 48 l35.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 13.95%\n",
      "# 49 l36.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 14.27%\n",
      "# 50 l37.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 14.99%\n",
      "# 51 l38.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'จับ' NUM:'2' Confidence: 14.79%\n",
      "# 52 l39.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'จับ' NUM:'2' Confidence: 14.57%\n",
      "# 53 l40.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'จับ' NUM:'2' Confidence: 14.43%\n",
      "# 54 l71.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 15.14%\n",
      "# 55 l72.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'หยุด' NUM:'5' Confidence: 14.62%\n",
      "# 56 l73.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 14.86%\n",
      "# 57 r30.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 17.30%\n",
      "# 58 r31.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 15.64%\n",
      "# 59 r32.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 16.79%\n",
      "# 60 r33.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 16.28%\n",
      "# 61 r34.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 16.45%\n",
      "# 62 r35.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 15.78%\n",
      "# 63 r36.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 17.17%\n",
      "# 64 r37.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 15.56%\n",
      "# 65 r38.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 16.47%\n",
      "# 66 r39.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 14.73%\n",
      "# 67 r40.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 15.63%\n",
      "# 68 r71.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 17.09%\n",
      "# 69 r72.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 17.52%\n",
      "# 70 r73.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 16.96%\n",
      "# 71 re30.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 14.64%\n",
      "# 72 re31.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'หยุด' NUM:'5' Confidence: 15.08%\n",
      "# 73 re32.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'หยุด' NUM:'5' Confidence: 16.04%\n",
      "# 74 re33.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'หยุด' NUM:'5' Confidence: 15.98%\n",
      "# 75 re34.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'หยุด' NUM:'5' Confidence: 15.22%\n",
      "# 76 re35.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'หยุด' NUM:'5' Confidence: 15.35%\n",
      "# 77 re36.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'หยุด' NUM:'5' Confidence: 15.89%\n",
      "# 78 re37.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 14.95%\n",
      "# 79 re38.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 15.10%\n",
      "# 80 re39.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 15.28%\n",
      "# 81 re40.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 15.82%\n",
      "# 82 re72.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 17.97%\n",
      "# 83 re73.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 18.60%\n",
      "# 84 re74.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 17.68%\n",
      "# 85 s30.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'หยุด' NUM:'5' Confidence: 18.93%\n",
      "# 86 s31.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'หยุด' NUM:'5' Confidence: 17.99%\n",
      "# 87 s32.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'หยุด' NUM:'5' Confidence: 18.87%\n",
      "# 88 s33.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'หยุด' NUM:'5' Confidence: 16.92%\n",
      "# 89 s34.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 15.38%\n",
      "# 90 s35.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 16.24%\n",
      "# 91 s36.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 15.75%\n",
      "# 92 s37.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'หยุด' NUM:'5' Confidence: 17.52%\n",
      "# 93 s38.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 19.09%\n",
      "# 94 s39.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'หยุด' NUM:'5' Confidence: 17.97%\n",
      "# 95 s40.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'หยุด' NUM:'5' Confidence: 19.02%\n",
      "# 96 s71.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 20.92%\n",
      "# 97 s72.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 19.83%\n",
      "# 98 s73.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 16.72%\n",
      "# 99 se30.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 15.46%\n",
      "# 100 se31.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 15.32%\n",
      "# 101 se32.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 16.39%\n",
      "# 102 se33.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 15.85%\n",
      "# 103 se34.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 15.68%\n",
      "# 104 se35.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 15.88%\n",
      "# 105 se36.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 15.37%\n",
      "# 106 se37.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 15.05%\n",
      "# 107 se38.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 15.00%\n",
      "# 108 se39.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 14.85%\n",
      "# 109 se40.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 14.54%\n",
      "# 110 se71.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 15.66%\n",
      "# 111 se72.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 16.44%\n",
      "# 112 se73.wav---------------------------------------------------\n",
      "INPUT SHAPE: (1, 32, 40, 1)\n",
      "Keyword Detected 'OTHER_KEYWORDS' | ORIGINAL: 'เลี้ยวขวา' NUM:'7' Confidence: 18.95%\n"
     ]
    }
   ],
   "source": [
    "TEST_PATH = os.path.join(\"Data_Thai\",\"test\")\n",
    "pred_demo = Keyword_Demo_v2(model_path, DATASET_JSON, plot=False)\n",
    "file_test_list = [filenames for _,_,filenames in os.walk(TEST_PATH)][0]\n",
    "for idx, file in enumerate(file_test_list):\n",
    "    print(f\"# {idx+1} {file}---------------------------------------------------\")\n",
    "    AUDIO_DATA_INPUT = os.path.join(\"Data_Thai/test/\",file)\n",
    "    keyword_result = pred_demo.predict(AUDIO_DATA_INPUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_demo2 = Keyword_Demo_v2(model_path, DATASET_JSON, plot=False)\n",
    "for idx, (dirpath, dirnames, filenames) in enumerate(os.walk(DATASET_PATH)):\n",
    "    print(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REAL-TIME SPEECH COMMAND RECOGNITION (INFERENCE PROCESS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEBUG - TEST PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vscode_audio import Audio\n",
    "x,sr = librosa.load(train_audio_sample, sr = 16000)\n",
    "x_augmented = random_shift(x)\n",
    "x_augmented = random_speed_up(x_augmented)\n",
    "x_augmented = random_change_pitch(x_augmented)\n",
    "Audio(x_augmented, sr)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "555a84b3913872e2e862f1e806eac0e56227ea6f84c49940b9c2017cb049ce4f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

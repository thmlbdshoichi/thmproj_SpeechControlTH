{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Audio Recognition using Tensorflow\n",
    "### Speech Recognition for Controlling Robot (THAI COMMAND EDITION)\n",
    "#### By. Arunwat Moonbung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "import pyaudio\n",
    "#import alsaaudio\n",
    "import time\n",
    "import wave\n",
    "\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,LabelBinarizer\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Keyword_realtime_demo:\n",
    "    def __init__(self, model_path, text_labels, plot=False, conf=0.7):\n",
    "        if os.path.exists(model_path):\n",
    "            self.model = keras.models.load_model(model_path)\n",
    "            #self.model.summary()\n",
    "        else:\n",
    "            print(\"!: Unable to Load model, Model directory not found.\")\n",
    "            self.model = None\n",
    "        if os.path.exists(text_labels):\n",
    "            with open(text_labels, \"r\", encoding=\"utf8\") as f:\n",
    "                data = json.load(f)\n",
    "            self.text_labels = [k for k in data.keys()]\n",
    "        else:\n",
    "            self.text_labels = None\n",
    "        self.plot = plot\n",
    "        self.conf = conf\n",
    "    \n",
    "    def start(self, DURATION):\n",
    "        # LOAD MFCCs LIST\n",
    "        # MFCCs = self.record_audio(DURATION=DURATION)\n",
    "        MFCCs = self.record_audio_alsa(DURATION=DURATION)\n",
    "        sT = time.time()\n",
    "        PREDICTED_LABELS = []\n",
    "        PREDICTED_CONFS = []\n",
    "        # EXTRACT IT ONE BY ONE\n",
    "        for idx, MFCC in enumerate(MFCCs):\n",
    "            # FEED IT TO PREDICT\n",
    "            #print(f\"#: PREDICTED RESULT {idx+1} of {len(MFCCs)}\")\n",
    "            predicted_label, predicted_conf = self.predict(MFCC)\n",
    "            PREDICTED_LABELS.append(predicted_label)\n",
    "            PREDICTED_CONFS.append(predicted_conf)\n",
    "        # MAKE A COMPARE BETWEEN CONF OF EACH LABEL OUTPUT\n",
    "        FINAL_RESULTS_INDEX = np.argmax(PREDICTED_CONFS)\n",
    "        FINAL_RESULTS = [PREDICTED_LABELS[FINAL_RESULTS_INDEX], PREDICTED_CONFS[FINAL_RESULTS_INDEX]]\n",
    "        print(f\"R: SUMMARIZE KEYWORDS DETECTED '{FINAL_RESULTS[0]}' with Confidence {FINAL_RESULTS[1]*100:.2f}%\\n\")\n",
    "        eT = time.time()\n",
    "        print(f\"INFERENCE USING {eT - sT}\")\n",
    "        return FINAL_RESULTS\n",
    "    \n",
    "    def predict(self, MFCCs_INPUT):\n",
    "        # PREDICT -> OUTPUT PROBABILITY\n",
    "        predictions = self.model.predict(MFCCs_INPUT)\n",
    "        predicted_index = np.argmax(predictions)\n",
    "        predicted_conf = predictions[0][predicted_index]\n",
    "        predicted_label = self.text_labels[predicted_index]\n",
    "        predicted_label_fix = self.text_labels[predicted_index]\n",
    "        if predicted_conf < self.conf:\n",
    "            predicted_label = \"ไม่มั่นใจ\"\n",
    "            print(f\"!: ERROR TO DETECT KEYWORD | '{predicted_label_fix}' WITH LOW CONFIDENCE {predicted_conf*100:.2f}%\")\n",
    "        else:\n",
    "            print(f\"#: KEYWORD DETECTED | '{predicted_label}' WITH CONFIDENCE: {predicted_conf*100:.2f}%\")\n",
    "            pass\n",
    "        return predicted_label, predicted_conf\n",
    "    \n",
    "    def preprocess_data_test(self, file_path, DURATION=1, n_mfcc=40, n_fft=4096, hop_length=512, NUM_SAMPLES_TO_CONSIDER=16000):\n",
    "        # CALCULATION FOR AUDIO FILES\n",
    "        SAMPLES_PER_TRACK = NUM_SAMPLES_TO_CONSIDER * DURATION\n",
    "        NUM_SAMPLES_PER_SEGMENT = int(SAMPLES_PER_TRACK/DURATION) # OR REPLACE DURATION WITH NUM_SEGMENTS\n",
    "        EXPECTED_MFCC = math.ceil(NUM_SAMPLES_PER_SEGMENT / hop_length) # EXPECTED NUMBERS OF MFCCs PER SEGMENT\n",
    "        # READ AUDIO FILE FROM .WAV FILE TO GET SIGNAL AND SR\n",
    "        signal, sr = librosa.load(file_path, sr=NUM_SAMPLES_TO_CONSIDER)\n",
    "        signal = self.pad_audio_sec(signal, DURATION, sr)\n",
    "        scaler = StandardScaler()\n",
    "        MFCCs_scaled = []\n",
    "        for s in range(DURATION): # DURATION = NUM_SEGMENTS\n",
    "            START_SAMPLE = int(NUM_SAMPLES_PER_SEGMENT * s)\n",
    "            END_SAMPLE = int(START_SAMPLE + NUM_SAMPLES_PER_SEGMENT)\n",
    "            MFCC = librosa.feature.mfcc(y=signal[START_SAMPLE:END_SAMPLE],\n",
    "                                        sr=sr, n_mfcc=n_mfcc,\n",
    "                                        hop_length=hop_length,n_fft=n_fft)\n",
    "            MFCC = MFCC.T\n",
    "            \n",
    "            if self.plot:\n",
    "                librosa.display.waveshow(signal[START_SAMPLE:END_SAMPLE], sr=sr)\n",
    "                #librosa.display.specshow(MFCC, sr=sr, hop_length=hop_length)\n",
    "                plt.title(f\"Audio Signal of {file_path} {s+1} of {DURATION}\")\n",
    "                plt.xlabel(\"Time (sec)\")\n",
    "                plt.ylabel(\"Amplitude\")\n",
    "                plt.show()\n",
    "                \n",
    "            MFCC_scaled = scaler.fit_transform(MFCC)\n",
    "            MFCC_scaled = MFCC_scaled.reshape(MFCC_scaled.shape[0], MFCC_scaled.shape[1], 1)\n",
    "            MFCC_scaled = MFCC_scaled[np.newaxis, ...]\n",
    "            if len(MFCC) == EXPECTED_MFCC:\n",
    "                MFCCs_scaled.append(MFCC_scaled)\n",
    "            else:\n",
    "                pass\n",
    "        return MFCCs_scaled\n",
    "\n",
    "    def record_audio(self, DURATION, CHANNELS=1, FORMAT=pyaudio.paInt16, n_fft=4096, NUM_SAMPLES_TO_CONSIDER=16000):\n",
    "        print(f\"####################################################################\")\n",
    "        print(f\"#: START RECORDING FOR {DURATION} SEC.. | PLEASE SPEAK KEYWORD NOW!!\")\n",
    "        print(f\"####################################################################\")\n",
    "        #time.sleep(0.5)\n",
    "        self.pyA = pyaudio.PyAudio()\n",
    "        self.pyAstream = self.pyA.open(format=FORMAT,channels=CHANNELS,\n",
    "                                    rate=NUM_SAMPLES_TO_CONSIDER, input=True, output=False,\n",
    "                                    frames_per_buffer=n_fft)\n",
    "        frames = [] #int(NUM_SAMPLES_TO_CONSIDER/n_fft * RECORD_SECONDS)\n",
    "        for i in range(0, int(round(NUM_SAMPLES_TO_CONSIDER/n_fft * DURATION))): \n",
    "            data = self.pyAstream.read(n_fft)\n",
    "            frames.append(data)\n",
    "        print(\"#: STOP RECORDING, SAVING CACHE FILE..\")\n",
    "        #frames_bytes = b''.join(frames)\n",
    "        #print('Size of Frames_bytes', len(frames_bytes))\n",
    "        self.pyAstream.stop_stream()\n",
    "        self.pyAstream.close()\n",
    "        self.pyA.terminate()\n",
    "        \n",
    "        # SAVE RECORDING FILE TO cacheSound.wav TO READ IT\n",
    "        try:\n",
    "            wf = wave.open('cacheSound.wav','wb')\n",
    "            wf.setnchannels(CHANNELS)\n",
    "            wf.setsampwidth(self.pyA.get_sample_size(FORMAT))\n",
    "            wf.setframerate(NUM_SAMPLES_TO_CONSIDER)\n",
    "            wf.writeframes(b''.join(frames))\n",
    "            wf.close()\n",
    "            return self.preprocess_data_test('cacheSound.wav', DURATION=DURATION)\n",
    "        except:\n",
    "            print(\"!: An Error occuring while saving .wav file\")\n",
    "            print(\"!: This will occur non keywords detected.\")\n",
    "            return [np.zeros((1, 32, 40, 1))]\n",
    "    \n",
    "    def record_audio_alsa(self, DURATION=1, CHANNELS=1, FORMAT='int16', n_fft=4096, NUM_SAMPLES_TO_CONSIDER=16000, device='default'):\n",
    "        print(f\"####################################################################\")\n",
    "        print(f\"#: START RECORDING FOR {DURATION} SEC.. | PLEASE SPEAK KEYWORD NOW!!\")\n",
    "        print(f\"####################################################################\")\n",
    "        try:\n",
    "            with open(\"cacheSound.raw\", \"wb\") as rf:\n",
    "                res = []\n",
    "                recorder = alsaaudio.PCM(alsaaudio.PCM_CAPTURE, alsaaudio.PCM_NORMAL,\n",
    "                channels=CHANNELS, rate=NUM_SAMPLES_TO_CONSIDER, format=alsaaudio.PCM_FORMAT_S16_LE, periodsize=2000, device=device)\n",
    "                while len(res) < 16000 * DURATION:\n",
    "                    l, data = recorder.read()\n",
    "                    a = np.frombuffer(data, dtype='int16')\n",
    "                    if len(data) != 0:\n",
    "                        rf.write(a)\n",
    "                        res.extend(a)\n",
    "                        time.sleep(.001)\n",
    "                rf.close()\n",
    "        except Exception as e:\n",
    "            print(\"!: An Error occuring while recording & saving .raw file\")\n",
    "            print(e)\n",
    "        print(f\"#: STOP RECORDING, SAVING AUDIO .RAW FILE..\")\n",
    "        print(f\"#: CONVERTING AUDIO RAW FILE -> .WAV FILE..\")\n",
    "        \n",
    "        try:\n",
    "            with open(\"cacheSound.raw\", \"rb\") as inp_f:\n",
    "                data = inp_f.read()\n",
    "                with wave.open(\"cacheSound.wav\", \"wb\") as out_f:\n",
    "                    out_f.setnchannels(CHANNELS)\n",
    "                    out_f.setsampwidth(2)\n",
    "                    out_f.setframerate(NUM_SAMPLES_TO_CONSIDER)\n",
    "                    out_f.writeframesraw(data)\n",
    "                    out_f.close()\n",
    "                    print(f\"#: WAV FILES HAS BEEN CONVERTED, SENDING TO AUDIO PREPROCESSING.\")\n",
    "                    print(f\"####################################################################\")\n",
    "            inp_f.close()\n",
    "            return self.preprocess_data_test('cacheSound.wav', DURATION=DURATION)\n",
    "        except Exception as e:\n",
    "            print(\"!: An Error occuring while converting raw file to .wav file\")\n",
    "            print(\"!: This will occur non keywords detected.\")\n",
    "            return [np.zeros((1, 32, 40, 1))]\n",
    "        \n",
    "    def pad_audio(self, signal, NUM_SAMPLES_TO_CONSIDER):\n",
    "        if len(signal) >= NUM_SAMPLES_TO_CONSIDER:\n",
    "            return signal[:NUM_SAMPLES_TO_CONSIDER]\n",
    "        else:\n",
    "            #return np.pad(signal, pad_width=(0, TOTAL_SAMPLE - len(signal)), mode='constant', constant_values=(0, 0)) # PAD หลัง\n",
    "            return np.pad(signal, pad_width=(NUM_SAMPLES_TO_CONSIDER - len(signal), 0), mode='constant', constant_values=(0, 0)) # PAD หน้า\n",
    "    \n",
    "    def pad_audio_sec(self, signal, DURATION, NUM_SAMPLES_TO_CONSIDER):\n",
    "        TOTAL_SAMPLE = DURATION*NUM_SAMPLES_TO_CONSIDER\n",
    "        if len(signal) >= TOTAL_SAMPLE:\n",
    "            return signal[:TOTAL_SAMPLE]\n",
    "        else:\n",
    "            #return np.pad(signal, pad_width=(0, TOTAL_SAMPLE - len(signal)), mode='constant', constant_values=(0, 0)) # PAD หลัง\n",
    "            return np.pad(signal, pad_width=(TOTAL_SAMPLE - len(signal), 0), mode='constant', constant_values=(0, 0)) # PAD หน้า"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Keyword_test = Keyword_realtime_demo(model_path='models/model.h5', text_labels='Data_Thai/classmap.json', plot=False, conf=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try: \n",
    "    while True:\n",
    "        print(\"\")\n",
    "        Keyword_test.start(DURATION=1)\n",
    "        print(\"\")\n",
    "        time.sleep(3)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"PROCESS END\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python SpeechControlTH_RT_ZCU104.py -m models/model.h5 -l Data_Thai/classmap.json -c 0.7 -dl 3 -d 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST ONCE WITH TEST SET\n",
    "for (dirpath, dirnames, filenames) in os.walk(os.path.join(\"Data_Thai\", \"test\")):\n",
    "    test_set = filenames\n",
    "    for idx, filename in enumerate(test_set):\n",
    "        print(f\"PREDICTING FILE: {filename}\")\n",
    "        MFCCs_TEST = Keyword_test.preprocess_data_test(os.path.join(\"Data_Thai\",\"test\",filename), DURATION=1)\n",
    "        for i in range(len(MFCCs_TEST)):\n",
    "            result = Keyword_test.predict(MFCCs_TEST[i])\n",
    "            #print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEBUG - TEST PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUGGING | SOUND RECORDING SYSTEM V1 (PYAUDIO)\n",
    "Keyword_test.record_audio(DURATION=1)\n",
    "print(\"FINISH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUGGING | SOUND RECORDING SYSTEM V2 (PYALSAAUDIO)\n",
    "# Keyword_test.record_audio_alsa(DURATION=1)\n",
    "# print(\"FINISH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUGGING | PREPROCESS AUDIO DATA INTO MFCCs READY SHAPE\n",
    "# DEBUGGING | PREDICTION\n",
    "MFCCs_DEBUG = Keyword_test.preprocess_data_test('cacheSound.wav', DURATION=1)\n",
    "print(len(MFCCs_DEBUG))\n",
    "print(MFCCs_DEBUG[0].shape)\n",
    "for i in range(len(MFCCs_DEBUG)):\n",
    "    result = Keyword_test.predict(MFCCs_DEBUG[i])\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileQuantizeWAV = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(os.path.join(\"Data_Thai\", \"quantizedata\")):\n",
    "    fileQuantizeWAV.extend(filenames)\n",
    "    break\n",
    "\n",
    "audio_dumps = []\n",
    "for i, filename in enumerate(fileQuantizeWAV):\n",
    "    MFCCs_DEBUG = Keyword_test.preprocess_data_test(os.path.join(\"Data_Thai\", \"quantizedata\", filename), DURATION=1)\n",
    "    MFCCs_ONCE = MFCCs_DEBUG[0]\n",
    "    audio_dumps.append(MFCCs_ONCE)\n",
    "    \n",
    "numpy_dumps = np.array(audio_dumps)\n",
    "np.save('audio_array', numpy_dumps)\n",
    "\n",
    "# load_np = np.load('audio_array.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Keyword_test.record_audio(DURATION=1)\n",
    "signal, sr = librosa.load('cacheSound.wav', sr=16000)\n",
    "\n",
    "if len(signal) >= 16000:\n",
    "    signal = signal[:16000]\n",
    "else:\n",
    "    signal = np.pad(signal, pad_width=(16000 - len(signal), 0), mode='constant', constant_values=(0, 0))\n",
    "    \n",
    "MFCCs = librosa.feature.mfcc(y=signal, n_mfcc=40,\n",
    "                                    hop_length=512,\n",
    "                                    n_fft=4096)\n",
    "MFCCs = MFCCs.T\n",
    "scaler = StandardScaler()\n",
    "MFCCs_scaled = scaler.fit_transform(MFCCs)\n",
    "MFCCs_scaled = MFCCs_scaled.reshape(MFCCs_scaled.shape[0], MFCCs_scaled.shape[1], 1)\n",
    "MFCCs_scaled = MFCCs_scaled[np.newaxis, ...]\n",
    "librosa.display.waveshow(signal, sr=16000)\n",
    "#librosa.display.specshow(MFCCs, sr=16000, hop_length=512)\n",
    "plt.title(f\"Sample of Cache Sound Signal\")\n",
    "plt.xlabel(\"Time (sec)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "#plt.colorbar()\n",
    "plt.show()\n",
    "#print(np.min(signal), np.max(signal))\n",
    "#print(len(signal))\n",
    "#print(MFCCs_scaled.shape)\n",
    "#print(MFCCs_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal2, sr2 = librosa.load('cacheSound.wav', sr=16000) # sr * T -> 22050 * 30\n",
    "MFCCs = librosa.feature.mfcc(y=signal2, n_mfcc=40,\n",
    "                                    hop_length=512,\n",
    "                                    n_fft=4096)\n",
    "librosa.display.waveshow(signal2, sr=sr2)\n",
    "plt.xlabel(\"TIME\")\n",
    "plt.ylabel(\"AMPLITUDE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DEBUG ALSAAUDIO (RECORD) + (PLAYBACK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import alsaaudio\n",
    "import time\n",
    "import numpy as np\n",
    "from playsound import playsound\n",
    "\n",
    "def record_audio_alsa(DURATION=1, CHANNELS=1, FORMAT='int16', n_fft=4096, NUM_SAMPLES_TO_CONSIDER=16000, device='default'):\n",
    "        print(f\"####################################################################\")\n",
    "        print(f\"#: START RECORDING FOR {DURATION} SEC.. | PLEASE SPEAK KEYWORD NOW!!\")\n",
    "        print(f\"####################################################################\")\n",
    "        try:\n",
    "            with open(\"cacheSound.raw\", \"wb\") as rf:\n",
    "                res = []\n",
    "                recorder = alsaaudio.PCM(alsaaudio.PCM_CAPTURE, alsaaudio.PCM_NORMAL,\n",
    "                channels=CHANNELS, rate=NUM_SAMPLES_TO_CONSIDER, format=alsaaudio.PCM_FORMAT_S16_LE, periodsize=2000, device=device)\n",
    "                while len(res) < 16000 * DURATION:\n",
    "                    l, data = recorder.read()\n",
    "                    a = np.frombuffer(data, dtype='int16')\n",
    "                    if len(data) != 0:\n",
    "                        rf.write(a)\n",
    "                        res.extend(a)\n",
    "                        time.sleep(.001)\n",
    "                rf.close()\n",
    "        except Exception as e:\n",
    "            print(\"!: An Error occuring while recording & saving .raw file\")\n",
    "            print(e)\n",
    "        print(f\"#: STOP RECORDING, SAVING AUDIO .RAW FILE..\")\n",
    "        print(f\"#: CONVERTING AUDIO RAW FILE -> .WAV FILE..\")\n",
    "        \n",
    "        try:\n",
    "            with open(\"cacheSound.raw\", \"rb\") as inp_f:\n",
    "                data = inp_f.read()\n",
    "                with wave.open(\"cacheSound.wav\", \"wb\") as out_f:\n",
    "                    out_f.setnchannels(CHANNELS)\n",
    "                    out_f.setsampwidth(2)\n",
    "                    out_f.setframerate(NUM_SAMPLES_TO_CONSIDER)\n",
    "                    out_f.writeframesraw(data)\n",
    "                    out_f.close()\n",
    "                    print(f\"#: WAV FILES HAS BEEN CONVERTED, SENDING TO AUDIO PREPROCESSING.\")\n",
    "                    print(f\"####################################################################\")\n",
    "            inp_f.close()\n",
    "            return \"RECORDING COMPLETED\n",
    "            #return self.preprocess_data_test('cacheSound.wav', DURATION=DURATION)\n",
    "        except Exception as e:\n",
    "            print(\"!: An Error occuring while converting raw file to .wav file\")\n",
    "            print(\"!: This will occur non keywords detected.\")\n",
    "            return \"RECORDING FAILED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_audio_alsa(DURATION=5)\n",
    "print(\"FINISH\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playsound('cacheSound.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 40, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 32, 40, 32)        320       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 40, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 20, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 20, 64)        18496     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 16, 20, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 10, 64)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 10, 128)        73856     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 8, 10, 128)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 5, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 5, 256)         295168    \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 4, 5, 256)         0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 2, 2, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               131200    \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 1032      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 520,072\n",
      "Trainable params: 520,072\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#CUT LAST LAYER\n",
    "#new_model = model.layers[-1].output\n",
    "model = keras.models.load_model('models_v3/model-best.h5')\n",
    "model_new = keras.models.Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "model_new.set_weights(model.get_weights())\n",
    "optimizer = keras.optimizers.Adam(learning_rate = 0.01)\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "model_new.compile(optimizer=optimizer, loss=loss_fn, metrics=[acc_metric])\n",
    "model_new.summary()\n",
    "model_new.save('model_bestepoch_cut_nd.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def play_audio_alsa(CHANNELS=1, NUM_SAMPLES_TO_CONSIDER=16000, PERIODSIZE=2000, device='default'):    \n",
    "    with wave.open('cacheSound.wav', 'rb') as sf:\n",
    "        total_sample = sf.getnframes()\n",
    "        sample_rate = sf.getframerate()\n",
    "        playback = alsaaudio.PCM(alsaaudio.PCM_PLAYBACK, alsaaudio.PCM_NORMAL, channels=CHANNELS, rate=NUM_SAMPLES_TO_CONSIDER, format=alsaaudio.PCM_FORMAT_S16_LE, periodsize=PERIODSIZE, device=device)\n",
    "        data = sf.readframes(PERIODSIZE)\n",
    "        for i in range(0, int(round(total_sample/PERIODSIZE))):\n",
    "            if data and i < int(round(total_sample/PERIODSIZE - 1)):\n",
    "                playback.write(data)\n",
    "                data = sf.readframes(PERIODSIZE)\n",
    "                time.sleep(0.001)\n",
    "            else:\n",
    "                print(\"OUT OF DATA\")\n",
    "                break\n",
    "        sf.close()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "555a84b3913872e2e862f1e806eac0e56227ea6f84c49940b9c2017cb049ce4f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
